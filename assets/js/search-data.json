{
  
    
        "post0": {
            "title": "KVN, Margaret & bingo - Part 3",
            "content": "In Part 1, we defined what we are trying to achieve (KVN whispering Margaret the drawn numbers) and what our proposed solution (a Neural Network). . In Part 2, we introduced the key concepts for KVN to be able to learn anything at all: loss functions, gradient descent and backpropagation. . Now it is time to start building the system we want to implement into KVN! To do so, we will use the Keras Python library. This library is specially designed to ease the creation and implementation of neural networks. Most of the things discussed above are already implemented in the library&#39;s methods. Let&#39;s start by loaing everything we will need. . Important: Even though we will use Python to implement the concepts, I aim to explain them in a way everyone can get the gist. . import numpy as np import matplotlib.pyplot as plt import tensorflow as tf from tensorflow import keras from tensorflow.keras import layers . Load the data . First of all, we need some examples for KVN to learn. Recall that we intend to make KVN learn by showing him examples of handwritten digits and telling him what number they represent. The set of examples used for learning are called the training set. Moreover, we also need some other examples that we can show KVN to evaluate him before the big night so we are sure he will deliver. These examples are called the test set. . Therefore, we need images of handwritten digits that we can show KVN so he can start learning. There is an extensively used public dataset called the MNIST database of handwritten digits. This dataset contains a training set of 60000 examples and a test set of 10000 examples. Luckily for us, this dataset is already implemented in the Keras library so we can directly use it! . (X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data() print(&quot;X_train original shape&quot;, X_train.shape) print(&quot;y_train original shape&quot;, y_train.shape) . X_train original shape (60000, 28, 28) y_train original shape (60000,) . As we can see, the training input set X_train contains 60000 greyscale images of size 28x28 px. The training label set y_train contains 60000 labels corresponding to each image. Let&#39;s look at some of the samples: . # Plot some MNIST examples. plt.figure(figsize=(8,2.5)) for i in range(3): plt.subplot(131+i) plt.imshow(X_train[i], cmap=&#39;gray_r&#39;) plt.title(f&quot;Digit: {y_train[i]}&quot;) plt.xticks([]) plt.yticks([]) . Format the data . As expected, these images are just what we need for KVN to learn to assist Margaret! Now, in order to use the images in the Keras implementation of the system, they have to be formatted in a particular manner (defined by the Keras library):: . Each pixel value goes from 0 to 255, but inputs need to be between 0 and 1. | The inputs must be vectors, not matrices. . 28x28 px -&gt; 784x1 px . | . There are ten categories which correspond to digits from $0$ to $9$. . # Format the data shape. X_train = X_train.reshape(60000, 784) X_test = X_test.reshape(10000, 784) # Change data type. X_train = X_train.astype(&#39;float32&#39;) X_test = X_test.astype(&#39;float32&#39;) y_train = y_train.astype(&#39;float32&#39;) y_test = y_test.astype(&#39;float32&#39;) # Normalize inputs to 0-1 interval. X_train /= 255 X_test /= 255 print(&quot;Training matrix shape&quot;, X_train.shape) print(&quot;Testing matrix shape&quot;, X_test.shape) . Training matrix shape (60000, 784) Testing matrix shape (10000, 784) . Build the neural network . Now that we have the data, we need to build the system that we will implement to KVN, we need to build the neural network! So far, the only network that we have seen had one (dummy) input layer, one hidden layer and one output layer. There are different types of layers. The one that is fully connected to the previous and the next layer (as the ones we have seen) is called Dense in Keras. For now, we will stick to this simple architechture (i.e. network structure) and see if it works. That is, our neural network will be constituted by: . An input layer with $784$ inputs (one per pixel). . | A hidden Dense layer with $n=30$ neurons. . Activation function: sigmoid | . | An output Dense layer with $n=10$ neurons. . Activation function: sigmoid | . | The choice of $n=30$ neurons in the hidden layer is rather arbitrary. Nonetheless, the number of neurons on the output layer is directly related to the number of categories we want for KVN to learn. Since we have $10$ categories (digits), we need $10$ neurons. The idea is that KVN&#39;s guess will be related to the neuron that has the higher activation. If the neuron corresponding to the digit 3 is the one with the higher activation, KVN is saying: &quot;A 3!&quot;. . Keras allows us to build our neural network in a very intuitive way. We generate what is called a Sequential model that basically lets us to add layers sequentially. When we add layers, there are ways to initialize the weights and biases (i.e. the parameter set) with different distributions. Nonetheless, we won&#39;t focus on this. Despite that, know that the initialization can influence the learning procedure. This makes sense since the initialization determines where in the mountain we start our downhill! . Enough chit chat, let&#39;s build KVN&#39;s system! . # Define KVN&#39;s system. kvn = keras.Sequential(name=&#39;KVN_system&#39;) # Add the hidden layer, a Dense layer with 30 neurons. # The first layer also requires specification of input dimensions. #Â Specify the activation function of the neurons too. kvn.add(layers.Dense(30, input_shape=(784,), activation=&#39;relu&#39;, name=&#39;hidden&#39;)) # Add the output layer, a Dense layer with 10 neurons (1 neuron per category). kvn.add(layers.Dense(10, activation=&#39;sigmoid&#39;, name=&#39;output&#39;)) # Save the initial weights and biases. kvn.save_weights(&#39;kvn_init_weights.h5&#39;) . Keras also allows us to check that we built the system we want. Here&#39;s how: . kvn.summary() . Model: &#34;KVN_system&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= hidden (Dense) (None, 30) 23550 _________________________________________________________________ output (Dense) (None, 10) 310 ================================================================= Total params: 23,860 Trainable params: 23,860 Non-trainable params: 0 _________________________________________________________________ . Insert system into KVN . Now that we have defined our system, we plug it into KVN. In actual terms, we compile the model (we won&#39;t delve into that either). The only thing that we need to know is that we need to specify the loss function (measure of how wrong KVN is), the optimizer (KVN&#39;s learning method) we want to use in the system and which metrics we want to get (the accuracy of KVN&#39;s predictions). . # Compile the model. kvn.compile( # Loss function (wrongness meter). loss=&#39;sparse_categorical_crossentropy&#39;, # Optimizer (learning method). optimizer=&#39;sgd&#39;, # Result evaluation. metrics=[&#39;accuracy&#39;] ) . KVN, learn! . Now that we have plugged the system into KVN it is time to start showing him the images of the numbers. 60000 of them. This phase is usually called the model fit because we are fitting all parameters to minimize the cost function. The validation set specified here answers to a similar idea as the test set. We have a set of examples to validate how KVN&#39;s is doing during the learning phase. . Tip: For proper development, we would want a validation set and a test set. Validation sets are used to try different strategies and asses which one is best during training. The test set should only be used at the end to provide an idea on how good KVN will work in the real situation. Let&#39;s learn! . batch_size = 64 # Number of training examples in each mini-batch. epochs = 10 # Number of epochs. # Fit the model and store information in history. history = kvn.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=0) . KVN, test time! . After this training session, KVN should have learned something. Now we want to see what has he learnt. To do so, let&#39;s evaluate KVN. Let&#39;s show him the test images (which he didn&#39;t use to learn although we already used them to see how he was doing) and see how good is he at identifying the digit present. . # Evaluate the performance of the system with the test set. scores = kvn.evaluate(X_test, y_test, verbose=0) # Scores contain the specified metrics. print(&quot;Test loss:&quot;, scores[0]) # Loss function by default. print(&quot;Test accuracy:&quot;, scores[1]) # Accuracy as asked. . Test loss: 0.2650674283504486 Test accuracy: 0.9253000020980835 . Damn, KVN! This is a remarkably good result! An accuracy of over $0.90$ means that KVN got the digit right more than $90 %$ of the time. This is quite a feature! . Let&#39;s check some of the KVN&#39;s good guesses and some of the KVN&#39;s bad guesses to get a flavor of what he has learned. . # Get the predicted class for each sample in X_test. predicted_classes = np.argmax(kvn.predict(X_test), axis=-1) # Check which are the good guesses and the bad guesses. correct_indexes = np.nonzero(y_test == predicted_classes)[0] incorrect_indexes = np.nonzero(y_test != predicted_classes)[0] # And see some examples. # Good guesses (predictions). plt.figure(figsize=(8,2.5)) for i, idx in enumerate(correct_indexes[:3]): plt.subplot(131+i) plt.imshow(X_test[i].reshape(28,28), cmap=&#39;gray_r&#39;) plt.title(f&quot;KVN&#39;s guess: {predicted_classes[idx]}, digit {y_test[idx]}&quot;) plt.xticks([]) plt.yticks([]) plt.tight_layout() # Bad guesses (predictions). plt.figure(figsize=(8,2.5)) for i, idx in enumerate(incorrect_indexes[:3]): plt.subplot(131+i) plt.imshow(X_test[idx].reshape(28,28), cmap=&#39;gray_r&#39;) plt.title(f&quot;KVN&#39;s guess: {predicted_classes[idx]}, digit {y_test[idx]}&quot;) plt.xticks([]) plt.yticks([]) plt.tight_layout() . Well, as we can see above, KVN got trouble learning to identify digits of rather poor handwritting but correctly identified more standard ones. So, for now, I think we can say that KVN did a good job! . Okay okay, good compared to what? The most trivial system would be to randomly pick a class. That is, that when we show KVN an image he randomly says a digit. In that case, he will be right, on average, $10 %$ of the time (because we have $10$ classes). So our system is quite better than the random system! Nonetheless, how good is the accuracy heavily depends on the problem. If we were trying to identify if a patient has cancer, for instance, this accuracy might still be too low. For the case at hand, that accuracy will absolutely do for good old Margaret. . KVN got a cookie! . . Did we get lucky? . As you might have realized, I made some arbitrary choices regarding some of the parameters such as the the number of neurons in the hidden layer or the epochs trained. Will KVN always perform that good independently of the choices we make? The short answer is no. . In the next (and final part), we will discover some of the factors that can dramatically impact the learning capabilities and performance of neural networks. We will talk about hyperparameters and regularization. . Part 1: Definition of Neural Networks at the problem at hand. Friendly context introduction. . | Part 2: The training building blocks: loss functions, gradient descent and backpropagation. . | .",
            "url": "https://bepuca.dev/machine%20learning/2020/06/13/kvn-part-3.html",
            "relUrl": "/machine%20learning/2020/06/13/kvn-part-3.html",
            "date": " â¢ Jun 13, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "KVN, Margaret & bingo - Part 2",
            "content": "In Part 1, we defined what we are trying to achieve (KVN whispering Margaret the drawn numbers) and what our proposed solution (a Neural Network). . Learning time! . Now we have an idea of what the new system we want to implement to KVN will look like. The problem is we need to be able to train this system. That is, we need a method for KVN to learn to identify the numbers using this system. . In more mathematical terms, learning means finding the optimal parameter set of weights $w$ and biases $b$ such that, at the end, KVN gets the digit right the maximum possible number of times. This is actually a big optimization problem and the concepts used in smaller problems hold. . The main idea required so that KVN can learn is that he needs to understand when he is wrong and how wrong he is. Once this is defined, he can learn to be less wrong the next time he tries (i.e. the parameters can be optimized). Ideally, if he tries a lot of times, he will eventually be as right as he can be with the particular system we design for him. . Wrongness meter (a.k.a Loss Function) . So, how can we define how wrong is KVN? The idea is to define what it is called a loss function or cost function $C$. This function must represent the distance between the truth (i.e. the correct digit) and the system&#39;s output (i.e. KVN&#39;s guess). That is, how wrong is KVN. . The two natural conditions that this function has to fulfill is that it has to depend on the output (otherwise it wouldn&#39;t make sense) and it has to be strictly positive (we will see in a moment why). Again, as in the activation function case, there are many different cost functions with different properties (but we won&#39;t enter into more detail here). Two of the most popular cost functions are: . The quadratic cost function: | . $$ C(w,b) = frac{1}{2n} sum_i | o(i) - a(i) |^2 $$ . This function represent the mean quadratic distance over all inputs $i$ (all images to learn) between the output corresponding to the input (guess of each image) and the correct answer $a$. It solely depends on the system parameters $w, b$. $n$ is the total number of inputs. This is the traditionally used cost function in optimization (or regression) problems. . The cross entropy cost function: | . $$ C(w,b) = - frac{1}{n} sum_i [o ln{a}+ (1-o) ln{(1-a)}] $$ . Notice that in this case, abusing notation, $a,o$ are equivalent to $a(i), o(i)$. This function is designed to solve some of the limitations of the quadratic cost function. In fact, cross-entropy is widely used in problems like the one we are trying to solve. . Now that KVN have a wrongness meter, how can we he use it to learn anything? . The downhill bike (a.k.a. Gradient Descent) . The typical method to solve optimization problems is what it is called gradient descent. This might sound quite complicated but the main idea is rather simple. To illustrate, let&#39;s define an arbitrary cost function that depends only on a single variable $x$. The situation is the following: . #collapse-hide import numpy as np import matplotlib.pyplot as plt # Define x grid. xx = np.linspace(-6,3,100) # Arbitrary cost function. def cost_fun(x): return 0.01*x**4 + 0.05*x**3 + 2 # Compute function shape. y = cost_fun(xx) fig = plt.figure(figsize=(6,2.4)) # Initial situation ax1 = plt.subplot(121) ax1.plot(xx, y, zorder=-1) ax1.scatter(2.5, cost_fun(2.5), color=&#39;r&#39;) ax1.arrow(2,3,-0.4,-0.4, width = 0.05, color=&#39;k&#39;) ax1.set_title(&quot;Initial situation&quot;) ax1.set_xlabel(&quot;$x$&quot;) ax1.set_ylabel(&quot;$C(x)$&quot;) # Final situation ax2 = plt.subplot(122) ax2.plot(xx, y, zorder=-1) ax2.scatter(xx[np.argmin(y)], min(y), color=&#39;lime&#39;) ax2.set_title(&quot;Final situation&quot;) ax2.set_xlabel(&quot;$x$&quot;) ax2.set_ylabel(&quot;$C(x)$&quot;); plt.tight_layout() . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; The idea behind gradient descent is quite simple. Imagine that initially the KVN&#39;s system is quite wrong and we start in the leftmost situation. We compute the cost function and it happens that we are far away from the minimum, which represents the least possible error we can have with our system (that is why we needed a positive function as having negative errors doesn&#39;t make much sense). Qualitatively, we would like to go downhill until we reach the minimum of the cost function, as in the leftmost plot. Following this explanation, we can imagine gradient descent as downhill biking. . Nonetheless, there is no easy way to know if we are at the very minimum. What we can do is look at our hill and see if we are in a slope. If that is the case, we ride our bike downhill a little bit before checking again. If we repeat this procedure many many times, we will end up, ideally, in the rightmost situation: we are in the minimum (i.e. KVN gets it right the maximum number of times the system allows him) so the system is optimized. . Mathematically, the slope is the derivative of the cost function with respect to the parameter set evaluated at the current parameter set. Therefore, the idea behind gradient descent is that we iteratively compute the derivative and update our parameter set such that we get closer to the minimum. Hopefully, in the end, we will reach the global minimum. The expression used for this update is: . $$ v rightarrow v&#39; = v - eta nabla C$$ . Here, $v$ is the parameter set $w, b$ of the system. $ eta$ is what it is called the learning rate which is equivalent to how long are our rides with the bycicle between slope checks. If it is too small, we will never reach the valley. If it is too big, we will end up going from one side of the valley to the other one, never reaching the bottom. The $ nabla C$ is the gradient of the cost function, which is equivalent to the slope of the mountain. There is a $-$ sign because we always want to go down. Remember that we are downhill biking! . The next question one might ask is: . Okay... but how exactly do you determine the slope of a mountain with a hell lot of dimensions?! . Remember that we have a lot of parameters and each parameter corresponds to a dimension. Thus, we have as many dimensions as parameters. The example above have only one dimension. Thus, this is a totally valid question. How would you know where down is if you were in a world that has 1000 dimensions? (Our world have three spatial dimensions). . As we have seen, the slope corresponds to the gradient. In computational sciences, gradients are usually computed by what is called finite differences. We won&#39;t discuss that here but the idea is that it requires to compute what happens to the cost function if we vary by a small amount a single parameter. And repeat for all parameters. This means that in order to determine the slope at every check, we have to compute the cost function as many times as parameters we have (a lot). And remember that in order to evaluate the cost functions we saw above we have to evaluate all training examples. Although this works, it is extremely slow. And by extremely I mean prohibitively slow. In our biking situation, night would fall upon us and no one wants to bike at night, for night is dark and full of terrors. . One way to speed things up is what is called stochastic gradient descent. The idea is that instead of using all input examples at each step, we use a random subsample of them, a mini-batch at each slope check. Then, the cost function is computed for this subsample and used to determine the slope. In the next check, a different subsample is used. This procedure is repeated until all training samples have been used which is said to complete an epoch of training. After each epoch, the procedure is started again. . Using this method, we only get an idea of where down is at each check, but an idea is sufficient to advance a bit. It is like our sense of equilibrium is a bit distorted but we always know more or less where down is. That way, KVN only has to look at a fraction of the images to learn a bit and is faster in dismounting, checking and riding the bike again. The path that KVN will follow with stochastic gradient descent will be less direct but the overall ride will also be much faster. Altough this method can improve the speed, the slope check is still too slow. . The slopemeter (a.k.a. Backpropagation) . The method usually used to compute the slope is the backpropagation algorithm. The idea is that using the chain rule of basic calculus, we can compute which effect a small perturbation of a parameter will have in the final cost function. These effects are actually the derivatives we were talking before, so what we are saying is that we use the chain rule to obtain simple forms to compute the derivatives. The name backpropagation comes from the fact that the algorithm starts at the output, and from the error in the cost function backpropagates through the network computing these perturbations and thus, obtaining the derivatives. . In the end, this means that each slope check, the network has to be used once per training sample (or image) in the mini-batch in the forward direction to compute the cost function (check how wrong KVN is in each image) and once per sample in the backward direction to compute the gradient (how different would be the error if some parameter was different). In the end, this method is much much faster than finite differences and allow neural networks to be really feasible. . My dear readers, we have finally revised all the building blocks required to understand the system we intend to implement into KVN for him to recognize the bingo digits. Time to get the job done! In the next part, we will finally teach KVN what it needs to know! . Part 1: Definition of Neural Networks at the problem at hand. Friendly context introduction. . | Part 3: Actual training of a Neural Network to identify handwritten digits. . | .",
            "url": "https://bepuca.dev/machine%20learning/2020/06/04/kvn-part-2.html",
            "relUrl": "/machine%20learning/2020/06/04/kvn-part-2.html",
            "date": " â¢ Jun 4, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "KVN, Margaret & bingo - Part 1",
            "content": "Neural Networks (NNs) are truly a hot topic these days. Or at least, the so-called Artificial Intelligence is. Nonetheless, I realized that, for most of my friends outside the machine learning niche, Neural Networks seem like dark magic (at least for the ones that care enough to ask). Here, I want to present an entertaining and illustrating narrative on what NNs are, how they work and an example of a problem that can (and actually is) solved by the technology. . Note: You will find here some of the mathematics and technical concepts. I introduce them for rigurosity and also to allow interested readers to delve deeper. I tried to make it approachable no matter what. So just skip whatever feels too technical and you will also understand the concepts, hopefully. If, despite that, you still have questions, please ask them in the comments! . Our very realistic problem . Imagine we are part of the ABC, the Amazing Bingo Club. This year it&#39;s the 100th anniversary of the club and a big event is coming up. We will have the biggest bingo) game the ABC has ever seen, for all the 29 members will be present! Moreover, we want to honor our beloved founder Margaret by letting her draw and call the numbers. But there is a problem. Margaret is blind now. . Let me say it again: Margaret. is. blind. :scream: . Fear not! We may have a solution. One of the members of the club has a KVN (pronounced Kevin), from the Final Space (much recommended series) universe. Meet KVN: . . KVN is a robot usually employed as a Deep Space Insanity Avoidance Companion. Now, we want to use it to read the numbers that Margaret draws and whisper them to her so she can then call the numbers aloud. The situation here is that KVN doesn&#39;t have a number recognition system implemented. That is, KVN can see but he is not able to recognize numbers... The good news are that we have access to KVN&#39;s main system, so if we are skilled enough, we could implement a digit recognizer into him. . But there is yet another problem (and we hope it to be the last). The ABC is in a really low budget so the numbers that Margaret will draw are handwritten numbers in small pieces of paper. Thus, we cannot just make KVN recognize some standard digits. Moreover, in the 100 years of the club, some numbers have been lost and replaced by many different members. So, in the end, we have a lot of different number styles within our bingo set. . In summary, then, we would like for KVN to be able to read handwritten digits similar to the ones below and whisper to Margaret: . It&#39;s a 2... . . Yeah, right, everything sounds pretty cool but how do we do it? . Well, one might think in the possibility to hardcode inside KVN&#39;s brain some rules to identify numbers such as the 2&#39;s have a semicircle on top, probably a loop on the bottom left, etc... As one can already divise, this is a ton of work for not so promising results. If that&#39;s not enough, it is also not that straightforward how to define such rules. . But what if we could show KVN a lot of examples of numbers so he can create his own rules to recognize them? What if we could do something like... . Us: Look KVN, this is a 2, this is also a 2, this is a 1, this is an 8, this is also an 8, etc. . | Us: *Showing him a new 2* What is this? . | KVN: A 2!!!! . | . Here is when Neural Networks (NN) enter the game. NNs are a tool that will allow KVN to learn to recognize digits as described above. . Note: What we are talking here is supervised learning of image classification, in the sense that we have labeled examples to teach KVN (e.g. images of 2 that we know are a 2) and the goal is to identify which number the image represents. NNs are used in a myriad of problems, not solely in supervised learning nor image classification. . First things first . When we talk about Neural Networks, we are actually talking about Artifical Neural Networks (ANNs). ANNs are vaguely inspired by the Biological Neural Networks (BNNs). BNNs or neural circuits are groups of interconnected neurons, a type of cell of the nervous system (including the brain). That is, your brain is full of BNN (among other things). . Neurons . These cells called neurons constitute a great part of our brain. Here a neuron: . . Their function, extremely simplified, is to transmit information. The way they work is the following: . A neuron receives a series of inputs from other neurons. | If the sum of these inputs is above a certain threshold, the neuron triggers and emits an output (that will go to other neurons). | More or less, we have 100 billion of these in our brain, which is A LOT. In principle, thanks to them we are able to sense and think but we will not delve deep into this. . The main idea we are interested in is: if we can learn with our brains which are constituted by neurons which are heavily interconnected... can we program artificial neurons, interconnect them and obtain an artificial brain that does something similar? Well, this is exactly what ANNs (NNs from now on) try to do. . Artificial neurons . In order to mimic the behaviour of neurons, artifical neurons are usually modeled as follows (image source): . . As we can see, these neurons have a series of inputs $i_i$, a weight $w_i$ associated with each input, an activation function $ sigma$ and an output $o$. . This might seem a bit obscure so let&#39;s try to clarify it a bit. The typical example used to explain artificial neurons is the following: Imagine there is a concert of our favourite group on Saturday and we want to decide whether or not to attend it. In order to take this decision, we consider several factors: . Will someone come with me? | Will it be good weather? | Can I go there by public transportation? | . To all these questions, which are my inputs $i_i$, affirmative answers (i.e. $1$) are good. But are they equally important? It might be the case that I don&#39;t really care if I have to go alone but I cannot withstand bad weather. How do I represent this? The weights $w_i$ are exactly for that. Bigger $w_i$ means bigger importance. Then, the activation function $ sigma$ is my decision function. A very simple function would be: . $$ o = sigma(i) = begin{cases} 1,&amp; text{if } sum_i w_i i_i gt threshold 0 ,&amp; text{if } sum_i w_i i_i lt threshold end{cases} $$That is, if the weighted input $ sum_i w_i i_i$ is greater than a threshold, the output $o$ will be $o=1$, I will go to the concert. In other words, only when the conditions I am considering to go to the concert are good enough for me I will attend the event. . In the neuron model, we can see that we have $ Sigma | sigma$. This is because the illustrative case is to use as an activation function the one explained above, which is simply the sum $ Sigma$ of the weighted inputs. But in general, the activation function used are a little bit more complicated than that. The idea is to introduce non-linearity, but it will stay out of the scope of this series. A general expression for these artificial neurons is: . $$ o = sigma big( sum_i w_i i_i + b big) $$ . Notice that a $b$, called bias, has appeared. This is equivalent to the threshold we were talking before, just a little rearranged. It can be thought as how difficult is to trigger the neuron. . There are many activation functions. The most popular are the following: . Sigmoid function: | . $$ sigma(x) = frac{1}{1+e^{-x}} $$ . Rectifier function (sometimes called ReLU): | . $$ sigma(x) = max(0,x) $$ . And their shape: . #collapse-hide import numpy as np import matplotlib.pyplot as plt # Define x grid. xx = np.linspace(-4,4,100) # Define response from the different activation functions. y_sig = 1/(1+np.exp(-xx)) y_relu = [max(0,x) for x in xx] # Plot the activation functions. plt.figure(figsize=(5,2)) # Sigmoid ax1 = plt.subplot(121) ax1.plot(xx,y_sig) ax1.set_title(&quot;Sigmoid&quot;) ax1.set_xlabel(&quot;$x$&quot;) ax1.set_ylabel(&quot;$ sigma(x)$&quot;) ax1.grid(alpha=0.3) # ReLU ax2 = plt.subplot(122) ax2.plot(xx,y_relu) ax2.set_title(&quot;ReLU&quot;) ax2.set_xlabel(&quot;$x$&quot;) ax2.set_ylabel(&quot;$ sigma(x)$&quot;) ax2.grid(alpha=0.3) plt.tight_layout(); . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; Neural Networks . Now that we have our neurons, we can build our neural networks by interconnecting them. This would be a simple of example of such networkNow that we have our neurons, we can build our neural networks by interconnecting them. This is simple of example of such network: . . This seems a bit more complicated but it&#39;s actually the same idea with just more neurons. The input layer is basically a representation of the input values (there are no neurons in the input layer). The output layer are the artifical neurons which produce the final outputs. The hidden layer, basically a layer which is not an input nor an output, is constituted by several neurons. Each neuron has its inputs, its outputs and its activation function. If we talk about parameters, each neuron has a set of weights $w$ (one for each input $i$ it receives) and a bias $b$. We can already see that for this very little example we already have a lot of parameters. This will be important later on. . This small &quot;brain&quot; works as following: there are a series of inputs that go to the hidden layer, each neuron in this layer produces an output that becomes an input for the next layer (the output layer in this case) and finally, the output layer neurons produce the final outputs. . Returning to our original problem, we want to implement one of this Neural Networks inside KVN such that when we give him an image of a number as an input, he will then whisper which number it is as an output. . Note: This example is what it is called a feedforward neural network. In these networks, there are no cycles. All information always goes forward from input to output. There are other types of neural networks with different properties, such as recurrent neural networks, but they are more complicated so we will stick to the &quot;easy&quot; case. . So far, we have defined the mini-brain we will implement into KVN. In the following parts (coming soon), we will explore how Neural Networks can learn a task and, ultimately, do what we want them to do. . Part 2: The training building blocks: loss functions, gradient descent and backpropagation. . | Part 3: Actual training of a Neural Network to identify handwritten digits. . | .",
            "url": "https://bepuca.dev/machine%20learning/2020/05/24/kvn-part-1.html",
            "relUrl": "/machine%20learning/2020/05/24/kvn-part-1.html",
            "date": " â¢ May 24, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "You can contact me at bernatpuig [at] gmail [dot] com . I am Bernat and I work at the intersection of data science and software engineering. Mine has been (and it is still is) a journey of beautiful discoveries. I started in physics and eventually transitioned to data science and software development. Today, I strive to embed machine learning into software solutions to help people and organizations alike focus on what matters. I thrive the most when working within diverse and multidisciplinary teams and I believe in the value of Lean and XP software principles. . Curiosity driven, virtually everything interests me. This has exposed me to a myriad of technologies, frameworks and tools and it has also led me into a never-ending quest for learning and personal growth. I always enjoy engaging discussions, so please reach out to me if you want to talk about anything you find interesting. . Also, I like to ski. Ah, I love skiing. . .",
          "url": "https://bepuca.dev/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ âsitemap.xmlâ | absolute_url }} | .",
          "url": "https://bepuca.dev/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}